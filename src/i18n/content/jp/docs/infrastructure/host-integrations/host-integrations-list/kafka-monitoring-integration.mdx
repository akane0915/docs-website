---
title: Kafkaモニタリングの統合
tags:
  - Integrations
  - On-host integrations
  - On-host integrations list
metaDescription: 'New Relic''s Kafka integration: how to install it and configure it, and what data it reports.'
translationType: machine
---

New Relic Kafka [on-host integration](/docs/integrations/host-integrations/getting-started/introduction-host-integrations) は、お使いの Kafka サービスからメトリクスと設定データをレポートします。ブローカー（ZooKeeperとBootstrapの両方）、プロデューサー、コンシューマー、トピックなど、クラスタの主要な要素をすべて計測します。

Kafkaインテグレーションをインストールして、どのようなデータを収集するかを確認してみましょう。当社の Java エージェントで Kafka を監視するには、 [Instrument Kafka message queues](/docs/agents/java-agent/instrumentation/instrument-kafka-message-queues) を参照してください。

## 互換性および要件 [#req]

当社のインテグレーションは、Kafkaのバージョン3.0以下に対応しています。

インテグレーションをインストールする前に、以下の要件を満たしていることを確認してください。

* New Relicアカウント。アカウントをお持ちでない場合[無料サインアップ](https://newrelic.com/signup)クレジットカードは不要です。

* KafkaがKubernetesやAmazon ECS上で ****稼働していない場合は、 [Kafkaが稼働しているホストにインフラストラクチャエージェント](/docs/infrastructure/install-infrastructure-agent/get-started/install-infrastructure-agent-new-relic) をインストールする必要があります。それ以外の場合は

  * Kubernetesで実行されている場合は、[これらの要件](/docs/monitor-service-running-kubernetes#requirements)をご覧ください。
  * ECSで実行されている場合は、[これらの要件](/docs/integrations/host-integrations/host-integrations-list/monitor-services-running-amazon-ecs)をご覧ください。

* Java 8以上

* すべてのブローカーでJMXが有効

* Javaベースのコンシューマとプロデューサのみで、JMXが有効な場合

* モニタリングされたトピックの総数が10000以下であること。

Kubernetes上で動作するKafkaの場合は、 [Kubernetesの要件](http://docs.newrelic.com/docs/monitor-service-running-kubernetes#requirements) を参照してください。

## インストールの準備 [#prepare]

Kafkaは、分散システムとして構築された複雑なソフトウェアです。そのため、データが正しく収集されるように、統合が必要なすべてのホストとサービスにコンタクトできるようにする必要があります。

### オートディスカバリー [#autodiscovery]

Kafkaの分散型の性質を考慮すると、ブローカーの実際の数とリストは通常、構成によって固定されておらず、代わりにかなり動的になります。このため、Kafkaインテグレーションでは、クラスタ内のブローカーのリストを自動的に検出する2つのメカニズムを提供しています。BootstrapとZookeeperです。どちらのメカニズムを使用するかは、監視対象のKafkaクラスタの設定によります。

#### ブートストラップ [#bootstrap]

[ブートストラップ・メカニズム](#bootstrap-discovery) を使用すると、統合はブートストラップ・ブローカーを使用して自動発見を行います。これは、アドレスがよく知られているブローカで、認識している他のブローカを尋ねることになります。ブートストラップ・ディスカバリーが機能するためには、統合は bootstrap_broker_host パラメータで提供されるアドレスで、このブローカーに連絡できる必要があります。

#### ズーキーパー [#zookeeper]

また、Kafkaインテグレーションは、ブローカーのリストを取得するために、 [Zookeeperサーバー](#zookeeper-discovery) と対話することもできる。そのためには、インテグレーションに以下のものを提供する必要がある。

* 連絡するZookeeperホストのリスト (zookeeper_hosts)
* ホストとの接続に必要な適切な認証シークレット。

Zookeeper は、知っているブローカーのリストと一緒に、それぞれのブローカーがどのような接続メカニズムをサポートしているかをアドバタイズする。

preferred_listenerパラメータを使用して、これらのメカニズムのいずれかを直接試みるようにKafka統合を設定できます。このパラメータが提供されていない場合、統合は、いずれかが成功するまで、アドバタイズされたすべての設定を持つブローカーへの連絡を試みます。

<Callout variant="tip">
  Zookeeper は、ブローカーを検出するためにのみ使用され、メトリクスは取得しません。
</Callout>

### トピックス一覧 [#topic-listing]

ブローカーによって処理されたトピックを正しくリストアップするために、統合はKafkaプロトコルを介してブローカーに連絡する必要があります。ブローカーの構成によっては、SSLやSASLをブローカーの構成に合わせて設定する必要があります。トピックにはDESCRIBEアクセスが必要です。

### ブローカーの監視（JMX） [#broker-monitoring]

Kafkaインテグレーションでは、Javaアプリケーションでメトリクスを交換するための標準的なJava拡張機能であるJMXを照会します。JMX は Kafka ブローカーではデフォルトでは有効になっておらず、メトリクス収集が正しく動作するためには有効にする必要があります。JMX は RMI を有効にする必要があり、RMI ポートは JMX と同じポートに設定する必要があります。

ユーザー名/パスワード認証、およびSSLを使用するようにJMXを設定することができます。ブローカーのJMX設定でこのような機能が有効になっている場合は、それに応じて統合を設定する必要があります。

自動発見がブートストラップに設定されている場合、ブートストラップブローカに定義されたJMX設定は、発見された他のすべてのブローカに適用されるため、ポートおよびその他の設定はすべてのブローカで同じにする必要があります。

<Callout variant="important">
  公共の場や信頼できないネットワークセグメントで、匿名または暗号化されていないJMX/RMIアクセスを可能にすることは、大きなセキュリティリスクをもたらすため、お勧めできません。
</Callout>

### 消費者のオフセット [#consumer-offset]

トピックの消費者と消費者グループのオフセット、およびラグは、 [KafkaOffsetSample](#KafkaOffsetSample-collection) として、 `CONSUMER_OFFSET=true` フラグを使って取得できますが、このフラグが有効な場合、インスタンスは他のSampleを収集しないため、別のインスタンスにする必要があります。

### プロデューサ/コンシューマの監視（JMX） [#producer]

また、Javaで書かれたプロデューサーとコンシューマーは、同じメカニズム（JMX）を通じて、より具体的なメタデータを得るために監視することができます。これにより、 [KafkaConsumerSamples と KafkaProducerSamples](#KafkaConsumerSample-collection) が生成されます。JMX がデフォルトで有効になっていないアプリケーションでは、JMX を有効にして設定する必要があります。

非JavaのプロデューサーとコンシューマーはJMXをサポートしていないため、Kafkaとの統合ではサポートされません。

### 接続条件 [#connectivity-requirements]

要約すると、統合機能を設定し、接続を許可する必要があります。

* `zookeeper_hosts` に記載されているホストを、Zookeeper プロトコルで、Zookeeper の認証メカニズムを使用して（ `autodiscover_strategy` が `zookeeper` に設定されている場合）実行する。
* `bootstrap_broker_host` で定義されたホストは、Kafka プロトコルを介して、Kafka ブローカーの認証/トランスポートメカニズムを使用します（ `autodiscover_strategy` が `bootstrap` に設定されている場合）。
* クラスター内のすべてのブローカーがKafkaのプロトコルとポートを介して、Kafkaブローカーの認証/トランスポートメカニズムを使用します。
* クラスター内のすべてのブローカーが、ブローカーのJMX構成で指定された認証/トランスポートメカニズムを使用して、JMXプロトコルとポートを介して。
* プロデューサ/コンシューマのモニタリングを行う場合は、JMXプロトコルとポートを介してプロデューサとコンシューマで指定されたすべてのプロデューサ/コンシューマ。コンシューマーのJMX設定は、ブローカーと同じである必要があります。

<Callout variant="important">
  **クラウドの場合：** デフォルトでは、AWSのSecurity Group（および他のクラウドプロバイダーでの同等のもの）は、必要なポートを開いていません。JMXが動作するためには、JMXポートとRMIポートの2つのポートが必要です。これらは、JMXを有効にするためにJVMを構成する際に同じ値に設定することができ、 **統合がブローカーに接続してメトリクスを収集できるようにするためには、** が開いている必要があります。
</Callout>

## インストールと有効化 [#install]

Kafkaインテグレーションをインストールするには、セットアップを選択します。

<CollapserGroup>
  <Collapser
    id="ecs-install"
    title="ECS"
  >
    [ECSで実行しているサービスを監視する](/docs/integrations/host-integrations/host-integrations-list/monitor-services-running-amazon-ecs)をご覧ください。
  </Collapser>

  ' '

  <Collapser
    id="k8s-install"
    title="Kubernetes"
  >
    [Kubernetesで実行しているサービスを監視する](/docs/monitor-service-running-kubernetes)をご覧ください。
  </Collapser>

  <Collapser
    id="linux-install"
    title="Linuxのインストール"
  >
    1. [インテグレーションのインストール](/docs/install-integrations-package) の指示に従って、ファイル名 `nri-kafka` を使用してください。

    2. ディレクトリをインテグレーションの設定フォルダに変更します。

       ```
       cd /etc/newrelic-infra/integrations.d
       ```

    3. サンプルの設定ファイルのコピー：

       ```
       sudo cp kafka-config.yml.sample kafka-config.yml
       ```

    4. `kafka-config.yml` ファイルを [構成設定](#config) で説明したように編集します。

    5. [](/docs/infrastructure/new-relic-infrastructure/configuration/start-stop-restart-check-infrastructure-agent-status)インフラストラクチャエージェントを再起動します。
  </Collapser>

  <Collapser
    id="windows-install"
    title="Windowsインストール"
  >
    1. `nri-kafka` のインストーラーイメージをダウンロードします。

       [http://download.newrelic.com/infrastructure_agent/windows/integrations/nri-kafka/nri-kafka-amd64-installer.exe](http://download.newrelic.com/infrastructure_agent/windows/integrations/nri-kafka/nri-kafka-amd64.msi)

    2. インストールするには、Windowsのコマンドプロンプトで次のコマンドを実行します。

       ```
       <var>PATH\TO\</var>nri-kafka-amd64-installer.exe
       ```

    3. インテグレーションのディレクトリ`C:\Program Files\New Relic\newrelic-infra\integrations.d\`で、以下を実行してサンプル設定ファイルのコピーを作成します。

       ```
       cp kafka-config.yml.sample kafka-config.yml
       ```

    4. `kafka-config.yml` 構成を [構成設定](#config) で説明したように編集します。

    5. [Infrastructureエージェントを再起動します](/docs/infrastructure/new-relic-infrastructure/configuration/start-stop-restart-check-infrastructure-agent-status)。
  </Collapser>
</CollapserGroup>

追加の注：

* **Advanced:** また、 [統合機能をtarballファイルからインストールすることも可能です](/docs/integrations/host-integrations/installation/install-host-integrations-built-new-relic#tarball) 。これにより、インストールと設定のプロセスを完全にコントロールすることができます。
* **オンホストインテグレーションは、自動的にアップデートしません。**最善の結果を得るため、[インテグレーションパッケージの更新](/docs/integrations/host-integrations/installation/update-infrastructure-host-integration-package)と[Infrastructureエージェントの更新](/docs/infrastructure/new-relic-infrastructure/installation/update-infrastructure-agent)を定期的に実施してください。

## インテグレーションの設定 [#config]

インストールの方法により、インテグレーションの設定方法はいくつかあります。

* Kubernetesで有効化した場合：[Kubernetes上で実行中のサービスの監視](/docs/monitor-service-running-kubernetes)を参照してください。
* Amazon ECSで有効化した場合：[ECS上で実行中のサービスの監視](/docs/integrations/host-integrations/host-integrations-list/monitor-services-running-amazon-ecs)を参照してください。
* オンホストでインストールした場合：インテグレーションのYAML設定ファイルのコンフィグを編集します。 `kafka-config.yml`.

統合の YAML 形式の設定では、必要なログイン認証情報を配置したり、データの収集方法を設定したりすることができます。どのオプションを変更するかは、お客様のセットアップや好みによります。環境全体をリモートで、または環境内の任意のノードで監視することができます。

設定ファイルには、`間隔`、`タイムアウト`、`inventory_source`など、すべてのインテグレーションに適用される共通設定があります。これらの共通設定の詳細については、[設定形式](/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-newer-configuration-format/#configuration-basics)ドキュメントを参照してください。

<Callout variant="important">
  レガシー設定/定義ファイルを引き続き使用する場合は、この[ドキュメント](/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/)を参照してください。
</Callout>

Kafka に関連する特定の設定は、設定ファイルの `env` セクションを使用して定義されます。これらの設定は、Broker、Zookeeper、JMX への接続や、その他のセキュリティ設定や機能を制御します。有効な設定のリストは、このドキュメントの次のセクションで説明します。

<Callout variant="important">
  この統合には、相互に排他的な2つの動作モードがあります。「コア」コレクションと"コンシューマ・オフセット・コレクション" CONSUMER_OFFSETパラメータで制御されます。

  * `CONSUMER_OFFSET = true` は消費者のオフセット収集モードで、 [KafkaOffsetSample](#KafkaOffsetSample-collection) を生成します。
  * `CONSUMER_OFFSET = false` はコアコレクションモードで、残りのサンプル([KafkaBrokerSample, KafkaTopicSample](#broker-collection), [KafkaProducerSample, KafkaConsumerSample](#KafkaConsumerSample-collection))を集めることができます。

  これらのモードは、消費者向けのオフセットコレクションが長い時間をかけて実行され、高いパフォーマンスが要求されるために分離されています。
</Callout>

これらの設定値は、いくつかの方法で定義できます。

* コンフィグファイルに直接値を追加する。これが最も一般的な方法です。
* `{{}}` 表記を使用して環境変数から値を置き換えます。これには、インフラストラクチャエージェントv1.14.0+が必要です。詳しくはこちら [](/docs/infrastructure/install-infrastructure-agent/configuration/configure-infrastructure-agent/#passthrough).
* シークレット管理を使用する。設定ファイル上でパスワードなどの常識的な情報が平文で公開されるのを防ぐために使用します。詳細については、 [Secrets management](/docs/integrations/host-integrations/installation/secrets-management) を参照してください。

### ラベル/カスタム属性 [#labels]

環境変数は、ライセンスキーなどの構成設定の管理に使用された後、Infrastructureエージェントにパススルーされます。この機能の利用手順に関しては、[Infrastructureエージェントを設定する](/docs/infrastructure/new-relic-infrastructure/configuration/configure-infrastructure-agent#passthrough)を参照してください。

また、ラベルを使ってメトリクスをさらに装飾することもできます。<br/> デフォルトのサンプル・コンフィグ・ファイルにはラベルの例が含まれていますが、必須ではないので、自分の好きなものを削除、変更、または新たに追加することができます。

```
  labels:
    env: production
    role: kafka
```

オンホストインテグレーション設定の一般的な構成の詳細については、[設定](/docs/integrations/integrations-sdk/file-specifications/host-integration-configuration-overview)を参照してください。

## KafkaBrokerSampleおよびKafkaTopicSampleコレクションの設定 [#broker-collection]

Kafkaインテグレーションは、Metrics(<strong> M</strong> )とInventory(<strong> I</strong> )の両方の情報を収集します。以下の **Applies To** カラムをチェックして、それぞれのコレクションに使用できる設定を確認してください。

' ' ' ' ' '

<table>
  <thead>
    <tr>
      <th style={{ width: "150px" }}>
        設定
      </th>

      <th>
        説明
      </th>

      <th>
        デフォルト
      </th>

      <th>
        適用先
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        **CLUSTER_NAME**
      </td>

      <td>
        監視対象のクラスターを一意に識別するためのユーザー定義名。 **必須**.
      </td>

      <td>
        該当なし
      </td>

      <td style={{ "text-align": "center" }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **KAFKA_VERSION**
      </td>

      <td>
        接続先のKafkaブローカーのバージョンで、最適なAPIバージョンを設定するために使用されます。ブローカーのバージョンと一致するか、それ以下でなければなりません。

        1.0.0より古いバージョンでは、一部の機能が失われている可能性があります。

        **ブローカーのバイナリ名がkafka_2.12-2.7.0の場合、使用するKafka apiのバージョンは2.7.0であり、その前の2.12はScala言語のバージョンであることに注意してください**.
      </td>

      <td>
        1.0.0
      </td>

      <td style={{ "text-align": "center" }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **オートディスカバー戦略**
      </td>

      <td>
        は、ブローカーを発見する方法。オプションは `zookeeper` または `bootstrap` 。
      </td>

      <td>
        飼育係
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **メトリクス**
      </td>

      <td>
        メトリクスのみの収集を有効にするには、 `true` に設定します。
      </td>

      <td>
        false
      </td>

      <td style={{ 'text-align': 'center' }}/>
    </tr>

    <tr>
      <td>
        **インベントリ**
      </td>

      <td>
        `true` に設定すると、インベントリのみの収集が可能になります。
      </td>

      <td>
        false
      </td>

      <td style={{ 'text-align': 'center' }}/>
    </tr>
  </tbody>
</table>

#### **Zookeeper 自動発見の引数** (only relevant when `autodiscover_strategy` is `zookeeper`): [#zookeeper-discovery]

' ' ' ' ' ' ' '

<table>
  <thead>
    <tr>
      <th style={{ width: "150px" }}>
        設定
      </th>

      <th>
        説明
      </th>

      <th>
        デフォルト
      </th>

      <th>
        適用先
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        **zookeeper_hosts**
      </td>

      <td>
        接続する必要のあるApache ZooKeeperホストの一覧 (JSON形式)

        **`CONSUMER_OFFSET` が `false` `KafkaBrokerSamples` と `KafkaTopicSamples` に設定されている場合、収集されます。**
      </td>

      <td>
        \[]
      </td>

      <td style={{ "text-align": "center" }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **zookeeper_auth_scheme**
      </td>

      <td>
        接続する際に使用する ZooKeeper の認証スキームを指定する。現在、サポートされているのは `digest` のみである。省略された場合、認証は行われない。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **zookeeper_auth_secret**
      </td>

      <td>
        接続時に使用する ZooKeeper 認証の秘密鍵。 `username:password` の形式で指定する。 `zookeeper_auth_scheme` が指定されている場合のみ必要。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **ZOOKEEPER_PATH**
      </td>

      <td>
        Kafka の設定を行う Zookeeper のノードを指定する。デフォルトは `/` 。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **優先リスナー**
      </td>

      <td>
        ブローカへの接続に特定のリスナーを使用します。設定されていない場合は、テスト接続に成功した最初のリスナーが使用されます。サポートされる値は、 `PLAINTEXT` 、 `SASL_PLAINTEXT` 、 `SSL` 、 `SASL_SSL` です。注： `SASL_*` プロトコルは、Kerberos（GSSAPI）認証のみをサポートしています。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>
  </tbody>
</table>

#### **ブートストラップ・ブローカー・ディスカバリー・アーギュメント** （ `autodiscover_strategy` が `ブートストラップ` の場合にのみ関係する）。 [#bootstrap-discovery]

' ' ' ' ' '

<table>
  <thead>
    <tr>
      <th style={{ width: "150px" }}>
        設定
      </th>

      <th>
        説明
      </th>

      <th>
        デフォルト
      </th>

      <th>
        適用先
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        **ブートストラップ\_ブローカー\_ホスト**
      </td>

      <td>
        ブートストラップ・ブローカーのホストです。

        **`CONSUMER_OFFSET` が `false` `KafkaBrokerSamples` と `KafkaTopicSamples` に設定されている場合、収集されます。**
      </td>

      <td>
        該当なし
      </td>

      <td style={{ "text-align": "center" }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **bootstrap_broker_kafka_port**
      </td>

      <td>
        ブートストラップ・ブローカーのKafkaポートです。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **bootstrap_broker_kafka_protocol**
      </td>

      <td>
        ブートストラップ・ブローカーへの接続に使用するプロトコルです。サポートされる値は、 `PLAINTEXT`, `SASL_PLAINTEXT`, `SSL`, `SASL_SSL` です。

        **`SASL_*` プロトコルは、Kerberos（GSSAPI）認証のみをサポートしていることに注意してください。**
      </td>

      <td>
        PLAINTEXT
      </td>

      <td style={{ "text-align": "center" }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **bootstrap_broker_jmx_port**
      </td>

      <td>
        クラスター内の各ブローカの収集に使用するJMXポートです。

        **検出されたすべてのブローカーは、このポートでJMXがアクティブになっている必要があります。**
      </td>

      <td>
        該当なし
      </td>

      <td style={{ "text-align": "center" }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **bootstrap_broker_jmx_user**
      </td>

      <td>
        クラスタ内の各ブローカの収集に使用するJMXユーザ。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **bootstrap_broker_jmx_password**
      </td>

      <td>
        クラスター内の各ブローカの収集に使用するJMXパスワードです。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>
  </tbody>
</table>

#### **JMX オプション（インスタンス上のすべての JMX 接続に適用されます）。**

' ' ' ' ' ' ' ' ' ' ' '

<table>
  <thead>
    <tr>
      <th style={{ width: "150px" }}>
        設定
      </th>

      <th>
        説明
      </th>

      <th>
        デフォルト
      </th>

      <th>
        適用先
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        **KEY_STORE**
      </td>

      <td>
        JMXクライアントのSSL証明書を含むキーストアのファイルパスです。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ "text-align": "center" }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **キー・ストア・パスワード**
      </td>

      <td>
        JMXのSSLキーストアのパスワードです。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **TRUST_STORE**
      </td>

      <td>
        JMXサーバーのSSL証明書を含むトラストキーストアのファイルパスです。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **trust_store_password**
      </td>

      <td>
        JMXトラストストアのパスワードです。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **default_jmx_user**
      </td>

      <td>
        メトリクスを収集するために JMX ホストに接続しているデフォルトのユーザーです。JMX ホストで username フィールドが省略された場合は、この値が使用されます。
      </td>

      <td>
        admin
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **default_jmx_password**
      </td>

      <td>
        JMX ホストに接続するためのデフォルトのパスワードです。JMX ホストでパスワードフィールドが省略された場合は、この値が使用されます。
      </td>

      <td>
        admin
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **タイムアウト**
      </td>

      <td>
        個々のJMXクエリのタイムアウト（単位：ミリ秒）。
      </td>

      <td>
        10000
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>
  </tbody>
</table>

#### **ブローカーのTLS接続オプション（ブローカープロトコルがSSLまたはSASL_SSLの場合に必要です）。**

' ' ' ' ' '

<table>
  <thead>
    <tr>
      <th style={{ width: "150px" }}>
        設定
      </th>

      <th>
        説明
      </th>

      <th>
        デフォルト
      </th>

      <th>
        適用先
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        **TLS_CA_FILE**
      </td>

      <td>
        SSLおよびSASL_SSLリスナー用の認証局ファイル（PEM形式）です。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ "text-align": "center" }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **TLS_CERT_FILE**
      </td>

      <td>
        SSLおよびSASL_SSLリスナー用のクライアント証明書ファイル（PEM形式）です。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **TLS_KEY_FILE**
      </td>

      <td>
        SSLおよびSASL_SSLリスナー用のクライアントキーファイル（PEM形式）です。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **TLS_INSECURE_SKIP_VERIFY**
      </td>

      <td>
        サーバーの証明書チェーンとホスト名の検証をスキップします。
      </td>

      <td>
        false
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>
  </tbody>
</table>

#### **ブローカーのSASLおよびKerberos接続オプション（ブローカープロトコルがSASL_PLAINTEXTまたはSASL_SSLの場合に必要）。**

' ' ' ' ' ' ' ' ' ' ' ' ' ' ' '

<table>
  <thead>
    <tr>
      <th style={{ width: "150px" }}>
        設定
      </th>

      <th>
        説明
      </th>

      <th>
        デフォルト
      </th>

      <th>
        適用先
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        **SASL_MECHANISM**
      </td>

      <td>
        使用するSASL認証のタイプです。サポートされているオプションは、 `SCRAM-SHA-512`, `SCRAM-SHA-256`, `PLAIN`, `GSSAPI` です。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ "text-align": "center" }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **SASL_USERNAME**
      </td>

      <td>
        PLAINおよびSCRAMメカニズムで必要なSASLユーザー名。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **SASL_PASSWORD**
      </td>

      <td>
        PLAINおよびSCRAMメカニズムで必要なSASLパスワード。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **sasl_gssapi_realm**
      </td>

      <td>
        GSSAPI機構で必要なKerberosレルム。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **sasl_gssapi_service_name**
      </td>

      <td>
        GSSAPI機構で必要なKerberosサービス名です。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **sasl_gssapi_username**
      </td>

      <td>
        GSSAPI機構で必要なKerberosユーザー名。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **sasl_gssapi_key_tab_path**
      </td>

      <td>
        GSSAPI機構で必要なKerberos key tabのパス。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **sasl_gssapi_kerberos_config_path**
      </td>

      <td>
        GSSAPI機構で必要なKerberosのコンフィグパスです。
      </td>

      <td>
        /etc/krb5.conf
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **sasl_gssapi_disable_fast_negotiation**
      </td>

      <td>
        FASTネゴシエーションを無効にします。
      </td>

      <td>
        false
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>
  </tbody>
</table>

#### **Broker Collectionのフィルタリング。**

' ' ' ' ' '

<table>
  <thead>
    <tr>
      <th style={{ width: "150px" }}>
        設定
      </th>

      <th>
        説明
      </th>

      <th>
        デフォルト
      </th>

      <th>
        適用先
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        **ローカルオンリーコレクション**
      </td>

      <td>
        設定されたブートストラップ・ブローカーに関連するメトリクスのみを収集します。 `autodiscover_strategy` が `bootstrap` である場合にのみ使用されます。

        **また、Kubernetesなどのディスカバリーを使用する環境ではtrueを設定する必要があります。これは、統合とディスカバリーの2回にわたってブローカーが検出され、データが重複してしまうためです。**

        **このフラグを有効にすると、KafkaTopicSampleの収集がスキップされることに注意してください。**
      </td>

      <td>
        false
      </td>

      <td style={{ "text-align": "center" }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **TOPIC_MODE**
      </td>

      <td>
        収集するトピックの数を決定します。オプションは `all`, `none`, `list`, or `regex` です。
      </td>

      <td>
        なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **TOPIC_LIST**
      </td>

      <td>
        監視するトピック名のJSON配列。 `topic_mode` が `list` に設定されている場合にのみ有効です。
      </td>

      <td>
        \[]
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **TOPIC_REGEX**
      </td>

      <td>
        監視するトピック名にマッチする Regex パターン。 `topic_mode` が `regex` に設定されている場合にのみ有効です。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **TOPIC_BUCKET**
      </td>

      <td>
        トピックコレクションを複数のインスタンスに分割するために使用します。 `< バケット番号>/<バケット数>` という形式でなければなりません。
      </td>

      <td>
        1/1
      </td>

      <td style={{ "text-align": "center" }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **コレクト・トピック・サイズ**
      </td>

      <td>
        メトリック・トピック・サイズを収集します。オプションは `true` または `false` で、デフォルトは `false` です。

        **これは、特に多くのトピックに対して収集するために、リソースを必要とする指標です。**
      </td>

      <td>
        false
      </td>

      <td style={{ "text-align": "center" }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **collect_topic_offset**
      </td>

      <td>
        メトリック・トピック・オフセットを収集します。オプションは `true` または `false` で、デフォルトは `false` です。

        **これは、特に多くのトピックに対して収集するために、リソースを必要とする指標です。**
      </td>

      <td>
        false
      </td>

      <td style={{ "text-align": "center" }}>
        M/I
      </td>
    </tr>
  </tbody>
</table>

## KafkaConsumerSampleおよびKafkaProducerSampleコレクションの設定 [#KafkaConsumerSample-collection]

Kafkaインテグレーションは、Metrics(<strong> M</strong> )とInventory(<strong> I</strong> )の両方の情報を収集します。以下の **Applies To** カラムをチェックして、それぞれのコレクションに使用できる設定を確認してください。

' ' ' ' ' ' ' ' ' ' ' '

<table>
  <thead>
    <tr>
      <th style={{ width: "150px" }}>
        設定
      </th>

      <th>
        説明
      </th>

      <th>
        デフォルト
      </th>

      <th>
        適用先
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        **CLUSTER_NAME**
      </td>

      <td>
        監視対象のクラスターを一意に識別するためのユーザー定義名。 **必須**.
      </td>

      <td>
        該当なし
      </td>

      <td style={{ "text-align": "center" }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **PRODUCERS**
      </td>

      <td>
        収集するプロデューサ。各プロバイダーについて、 `name`, `hostname`, `port`, `username`, `password` を JSON 形式で提供することができます。 `name` は、Kafka に表示されるプロデューサーの名前です。 `hostname`, `port`, `username`, `password` は、オプションの JMX 設定で、指定されていない場合はデフォルトを使用します。KafkaProducerSample を生成するために必要です。

        **例： `[{"name":"myProducer","host":"localhost","port": 24,"username":"me","password":"secret"}] ←ここをクリックしてください。`**
      </td>

      <td>
        \[]
      </td>

      <td style={{ "text-align": "center" }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **コンシューマー**
      </td>

      <td>
        収集するコンシューマー。各コンシューマーに対して、 `name`, `hostname`, `port`, `username`, `password` を JSON 形式で指定することができます。 `name` は、Kafka に表示されるコンシューマーの名前です。 `hostname`, `port`, `username`, `password` は、オプションの JMX 設定で、指定されていない場合はデフォルトを使用します。KafkaConsumerSample を生成するために必要です。

        **例： `[{"name":"myConsumer","host":"localhost","port": 24,"username":"me","password":"secret"}] [例：`**
      </td>

      <td>
        \[]
      </td>

      <td style={{ "text-align": "center" }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **デフォルト\_jmx_host**
      </td>

      <td>
        JMX メトリクスを収集するためのデフォルトのホストです。プロデューサまたはコンシューマの構成でホストフィールドが省略された場合、この値が使用されます。
      </td>

      <td>
        localhost
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **default_jmx_port**
      </td>

      <td>
        JMX メトリクスを収集するためのデフォルトのポートです。プロデューサまたはコンシューマの設定でポートフィールドが省略された場合、この値が使用されます。
      </td>

      <td>
        9999
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **default_jmx_user**
      </td>

      <td>
        メトリクスを収集するために JMX ホストに接続しているデフォルトのユーザー。プロデューサまたはコンシューマの構成で username フィールドが省略された場合は、この値が使用されます。
      </td>

      <td>
        admin
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **default_jmx_password**
      </td>

      <td>
        JMX ホストに接続するためのデフォルトのパスワードです。プロデューサまたはコンシューマの設定でパスワードフィールドが省略された場合、この値が使用されます。
      </td>

      <td>
        admin
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **メトリクス**
      </td>

      <td>
        メトリクスのみの収集を有効にするには、 `true` に設定します。
      </td>

      <td>
        false
      </td>

      <td style={{ 'text-align': 'center' }}/>
    </tr>

    <tr>
      <td>
        **インベントリ**
      </td>

      <td>
        `true` に設定すると、インベントリのみの収集が可能になります。
      </td>

      <td>
        false
      </td>

      <td style={{ 'text-align': 'center' }}/>
    </tr>
  </tbody>
</table>

#### **JMX の SSL とタイムアウトのオプション（インスタンス上のすべての JMX 接続に適用されます）。**

' ' ' ' ' ' ' '

<table>
  <thead>
    <tr>
      <th style={{ width: "150px" }}>
        設定
      </th>

      <th>
        説明
      </th>

      <th>
        デフォルト
      </th>

      <th>
        適用先
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        **KEY_STORE**
      </td>

      <td>
        JMXクライアントのSSL証明書を含むキーストアのファイルパスです。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ "text-align": "center" }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **キー・ストア・パスワード**
      </td>

      <td>
        JMXのSSLキーストアのパスワードです。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **TRUST_STORE**
      </td>

      <td>
        JMXサーバーのSSL証明書を含むトラストキーストアのファイルパスです。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **trust_store_password**
      </td>

      <td>
        JMXトラストストアのパスワードです。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **タイムアウト**
      </td>

      <td>
        個々のJMXクエリのタイムアウト（単位：ミリ秒）。
      </td>

      <td>
        10000
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>
  </tbody>
</table>

## KafkaOffsetSampleコレクションの設定 [#KafkaOffsetSample-collection]

Kafkaインテグレーションは、Metrics(<strong> M</strong> )とInventory(<strong> I</strong> )の両方の情報を収集します。以下の **Applies To** カラムをチェックして、それぞれのコレクションに使用できる設定を確認してください。

' ' ' ' ' '

<table>
  <thead>
    <tr>
      <th style={{ width: "150px" }}>
        設定
      </th>

      <th>
        説明
      </th>

      <th>
        デフォルト
      </th>

      <th>
        適用先
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        **CLUSTER_NAME**
      </td>

      <td>
        監視対象のクラスターを一意に識別するためのユーザー定義名。 **必須**.
      </td>

      <td>
        該当なし
      </td>

      <td style={{ "text-align": "center" }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **KAFKA_VERSION**
      </td>

      <td>
        接続先のKafkaブローカーのバージョンで、最適なAPIバージョンを設定するために使用されます。ブローカーのバージョンと一致するか、それ以下でなければなりません。

        1.0.0より古いバージョンでは、一部の機能が失われている可能性があります。

        **ブローカーのバイナリ名がkafka_2.12-2.7.0の場合、使用するKafka apiのバージョンは2.7.0であり、その前の2.12はScala言語のバージョンであることに注意してください**.
      </td>

      <td>
        1.0.0
      </td>

      <td style={{ "text-align": "center" }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **オートディスカバー戦略**
      </td>

      <td>
        は、ブローカーを発見する方法。オプションは `zookeeper` または `bootstrap` 。
      </td>

      <td>
        飼育係
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **consumer_offset**
      </td>

      <td>
        trueに設定すると、KafkaOffsetSampleにコンシューマーのオフセットデータを投入します。

        **このオプションは、Broker/Consumer/Producerの収集をスキップし、KafkaOffsetSampleのみを収集することに注意してください。**
      </td>

      <td>
        false
      </td>

      <td style={{ "text-align": "center" }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **consumer_group_regex**
      </td>

      <td>
        オフセット統計を収集する消費者グループにマッチする正規表現パターンです。これは、300個の消費者グループの統計を収集する場合に限られます。

        注： `consumer_groups` は非推奨となったため、代わりにこの引数を使用してください。このオプションは、CONSUMER_OFFSETがtrueのときに設定する必要があります。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ "text-align": "center" }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **メトリクス**
      </td>

      <td>
        メトリクスのみの収集を有効にするには、 `true` に設定します。
      </td>

      <td>
        false
      </td>

      <td style={{ 'text-align': 'center' }}/>
    </tr>

    <tr>
      <td>
        **インベントリ**
      </td>

      <td>
        `true` に設定すると、インベントリのみの収集が可能になります。
      </td>

      <td>
        false
      </td>

      <td style={{ 'text-align': 'center' }}/>
    </tr>
  </tbody>
</table>

#### **Zookeeper 自動発見の引数** (only relevant when `autodiscover_strategy` is `zookeeper`):

' ' ' ' ' ' ' '

<table>
  <thead>
    <tr>
      <th style={{ width: "150px" }}>
        設定
      </th>

      <th>
        説明
      </th>

      <th>
        デフォルト
      </th>

      <th>
        適用先
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        **zookeeper_hosts**
      </td>

      <td>
        接続する必要のあるApache ZooKeeperホストの一覧 (JSON形式)

        **`CONSUMER_OFFSET` が `false` `KafkaBrokerSamples` と `KafkaTopicSamples` に設定されている場合、収集されます。**
      </td>

      <td>
        \[]
      </td>

      <td style={{ "text-align": "center" }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **zookeeper_auth_scheme**
      </td>

      <td>
        接続する際に使用する ZooKeeper の認証スキームを指定する。現在、サポートされているのは `digest` のみである。省略された場合、認証は行われない。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **zookeeper_auth_secret**
      </td>

      <td>
        接続時に使用する ZooKeeper 認証の秘密鍵。 `username:password` の形式で指定する。 `zookeeper_auth_scheme` が指定されている場合のみ必要。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **ZOOKEEPER_PATH**
      </td>

      <td>
        Kafka の設定を行う Zookeeper のノードを指定する。デフォルトは `/` 。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **優先リスナー**
      </td>

      <td>
        ブローカへの接続に特定のリスナーを使用します。設定されていない場合は、テスト接続に成功した最初のリスナーが使用されます。サポートされる値は、 `PLAINTEXT` 、 `SASL_PLAINTEXT` 、 `SSL` 、 `SASL_SSL` です。注： `SASL_*` プロトコルは、Kerberos（GSSAPI）認証のみをサポートしています。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>
  </tbody>
</table>

#### **ブートストラップ・ブローカー・ディスカバリー・アーギュメント** （ `autodiscover_strategy` が `ブートストラップ` の場合にのみ関係する）。

' ' ' ' ' '

<table>
  <thead>
    <tr>
      <th style={{ width: "150px" }}>
        設定
      </th>

      <th>
        説明
      </th>

      <th>
        デフォルト
      </th>

      <th>
        適用先
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        **ブートストラップ\_ブローカー\_ホスト**
      </td>

      <td>
        ブートストラップ・ブローカーのホストです。

        **`CONSUMER_OFFSET` が `false` `KafkaBrokerSamples` と `KafkaTopicSamples` に設定されている場合、収集されます。**
      </td>

      <td>
        該当なし
      </td>

      <td style={{ "text-align": "center" }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **bootstrap_broker_kafka_port**
      </td>

      <td>
        ブートストラップ・ブローカーのKafkaポートです。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **bootstrap_broker_kafka_protocol**
      </td>

      <td>
        ブートストラップ・ブローカーへの接続に使用するプロトコルです。サポートされる値は、 `PLAINTEXT`, `SASL_PLAINTEXT`, `SSL`, `SASL_SSL` です。

        **`SASL_*` プロトコルは、Kerberos（GSSAPI）認証のみをサポートしていることに注意してください。**
      </td>

      <td>
        PLAINTEXT
      </td>

      <td style={{ "text-align": "center" }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **bootstrap_broker_jmx_port**
      </td>

      <td>
        クラスター内の各ブローカの収集に使用するJMXポートです。

        **検出されたすべてのブローカーは、このポートでJMXがアクティブになっている必要があります。**
      </td>

      <td>
        該当なし
      </td>

      <td style={{ "text-align": "center" }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **bootstrap_broker_jmx_user**
      </td>

      <td>
        クラスタ内の各ブローカの収集に使用するJMXユーザ。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **bootstrap_broker_jmx_password**
      </td>

      <td>
        クラスター内の各ブローカの収集に使用するJMXパスワードです。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>
  </tbody>
</table>

#### **JMX の SSL とタイムアウトのオプション（インスタンス上のすべての JMX 接続に適用されます）。**

' ' ' ' ' ' ' ' ' ' ' '

<table>
  <thead>
    <tr>
      <th style={{ width: "150px" }}>
        設定
      </th>

      <th>
        説明
      </th>

      <th>
        デフォルト
      </th>

      <th>
        適用先
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        **KEY_STORE**
      </td>

      <td>
        JMXクライアントのSSL証明書を含むキーストアのファイルパスです。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ "text-align": "center" }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **キー・ストア・パスワード**
      </td>

      <td>
        JMXのSSLキーストアのパスワードです。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **TRUST_STORE**
      </td>

      <td>
        JMXサーバーのSSL証明書を含むトラストキーストアのファイルパスです。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **trust_store_password**
      </td>

      <td>
        JMXトラストストアのパスワードです。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **default_jmx_user**
      </td>

      <td>
        メトリクスを収集するために JMX ホストに接続しているデフォルトのユーザーです。JMX ホストで username フィールドが省略された場合は、この値が使用されます。
      </td>

      <td>
        admin
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **default_jmx_password**
      </td>

      <td>
        JMX ホストに接続するためのデフォルトのパスワードです。JMX ホストでパスワードフィールドが省略された場合は、この値が使用されます。
      </td>

      <td>
        admin
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **タイムアウト**
      </td>

      <td>
        個々のJMXクエリのタイムアウト（単位：ミリ秒）。
      </td>

      <td>
        10000
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>
  </tbody>
</table>

#### **ブローカーのTLS接続オプション（ブローカープロトコルがSSLまたはSASL_SSLの場合に必要です）。**

' ' ' ' ' '

<table>
  <thead>
    <tr>
      <th style={{ width: "150px" }}>
        設定
      </th>

      <th>
        説明
      </th>

      <th>
        デフォルト
      </th>

      <th>
        適用先
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        **TLS_CA_FILE**
      </td>

      <td>
        SSLおよびSASL_SSLリスナー用の認証局ファイル（PEM形式）です。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ "text-align": "center" }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **TLS_CERT_FILE**
      </td>

      <td>
        SSLおよびSASL_SSLリスナー用のクライアント証明書ファイル（PEM形式）です。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **TLS_KEY_FILE**
      </td>

      <td>
        SSLおよびSASL_SSLリスナー用のクライアントキーファイル（PEM形式）です。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **TLS_INSECURE_SKIP_VERIFY**
      </td>

      <td>
        サーバーの証明書チェーンとホスト名の検証をスキップします。
      </td>

      <td>
        false
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>
  </tbody>
</table>

#### **ブローカーのSASLおよびKerberos接続オプション（ブローカープロトコルがSASL_PLAINTEXTまたはSASL_SSLの場合に必要）。**

' ' ' ' ' ' ' ' ' ' ' ' ' ' ' '

<table>
  <thead>
    <tr>
      <th style={{ width: "150px" }}>
        設定
      </th>

      <th>
        説明
      </th>

      <th>
        デフォルト
      </th>

      <th>
        適用先
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        **SASL_MECHANISM**
      </td>

      <td>
        使用するSASL認証のタイプです。サポートされているオプションは、 `SCRAM-SHA-512`, `SCRAM-SHA-256`, `PLAIN`, `GSSAPI` です。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ "text-align": "center" }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **SASL_USERNAME**
      </td>

      <td>
        PLAINおよびSCRAMメカニズムで必要なSASLユーザー名。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **SASL_PASSWORD**
      </td>

      <td>
        PLAINおよびSCRAMメカニズムで必要なSASLパスワード。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **sasl_gssapi_realm**
      </td>

      <td>
        GSSAPI機構で必要なKerberosレルム。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **sasl_gssapi_service_name**
      </td>

      <td>
        GSSAPI機構で必要なKerberosサービス名です。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **sasl_gssapi_username**
      </td>

      <td>
        GSSAPI機構で必要なKerberosユーザー名。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **sasl_gssapi_key_tab_path**
      </td>

      <td>
        GSSAPI機構で必要なKerberos key tabのパス。
      </td>

      <td>
        該当なし
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **sasl_gssapi_kerberos_config_path**
      </td>

      <td>
        GSSAPI機構で必要なKerberosのコンフィグパスです。
      </td>

      <td>
        /etc/krb5.conf
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>

    <tr>
      <td>
        **sasl_gssapi_disable_fast_negotiation**
      </td>

      <td>
        FASTネゴシエーションを無効にします。
      </td>

      <td>
        false
      </td>

      <td style={{ 'text-align': 'center' }}>
        M/I
      </td>
    </tr>
  </tbody>
</table>

## 設定の例 [#examples]

<CollapserGroup>
  <Collapser
    id="example1"
    title="zookeeper discovery"
  >
    この構成では、2つの異なるJMXホストからブローカーを検出するすべてのトピックを含むMetricsとInventoryを収集します。

    ```
    integrations:
      - name: nri-kafka
        env:
          CLUSTER_NAME: testcluster1
          KAFKA_VERSION: "1.0.0"
          AUTODISCOVER_STRATEGY: zookeeper
          ZOOKEEPER_HOSTS: '[{"host": "localhost", "port": 2181}, {"host": "localhost2", "port": 2181}]'
          ZOOKEEPER_AUTH_SECRET: "username:password"
          ZOOKEEPER_PATH: "/kafka-root"
          DEFAULT_JMX_USER: username
          DEFAULT_JMX_PASSWORD: password
          TOPIC_MODE: all
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
    ```
  </Collapser>

  <Collapser
    id="example2"
    title="zookeeper ssl discovery"
  >
    この構成では、SSLを使用したJMXホストからブローカーを検出して、MetricsとInventoryを収集します。

    ```
    integrations:
      - name: nri-kafka
        env:
          CLUSTER_NAME: testcluster1
          KAFKA_VERSION: "1.0.0"
          AUTODISCOVER_STRATEGY: zookeeper
          ZOOKEEPER_HOSTS: '[{"host": "localhost", "port": 2181}]'
          ZOOKEEPER_AUTH_SECRET: "username:password"
          ZOOKEEPER_PATH: "/kafka-root"
          DEFAULT_JMX_USER: username
          DEFAULT_JMX_PASSWORD: password

          KEY_STORE: "/path/to/your/keystore"
          KEY_STORE_PASSWORD: keystore_password
          TRUST_STORE: "/path/to/your/truststore"
          TRUST_STORE_PASSWORD: truststore_password

          TIMEOUT: 10000  #The timeout for individual JMX queries in milliseconds.
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
    ```
  </Collapser>

  <Collapser
    id="example3"
    title="ブートストラップ・ディスカバリー"
  >
    この構成では、1つのブートストラップブローカから、ブローカを検出するすべてのトピックを含むメトリクスとインベントリを収集します。

    ```
    integrations:
      - name: nri-kafka
        env:
          CLUSTER_NAME: testcluster1
          AUTODISCOVER_STRATEGY: bootstrap
          BOOTSTRAP_BROKER_HOST: localhost
          BOOTSTRAP_BROKER_KAFKA_PORT: 9092
          BOOTSTRAP_BROKER_KAFKA_PROTOCOL: PLAINTEXT
          BOOTSTRAP_BROKER_JMX_PORT: 9999  # This same port will be used to connect to all discover broker JMX
          BOOTSTRAP_BROKER_JMX_USER: admin
          BOOTSTRAP_BROKER_JMX_PASSWORD: password

          LOCAL_ONLY_COLLECTION: false

          COLLECT_BROKER_TOPIC_DATA: true
          TOPIC_MODE: "all"
          COLLECT_TOPIC_SIZE: false
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
    ```
  </Collapser>

  <Collapser
    id="example4"
    title="boootstrap discovery tls"
  >
    この設定では、TLSプロトコルでリッスンする1つのブートストラップブローカから、ブローカを発見したメトリクスのみを収集します。

    ```
    integrations:
      - name: nri-kafka
        env:
          METRICS: true
          CLUSTER_NAME: testcluster1
          AUTODISCOVER_STRATEGY: bootstrap
          BOOTSTRAP_BROKER_HOST: localhost
          BOOTSTRAP_BROKER_KAFKA_PORT: 9092
          BOOTSTRAP_BROKER_KAFKA_PROTOCOL: SSL
          BOOTSTRAP_BROKER_JMX_PORT: 9999
          BOOTSTRAP_BROKER_JMX_USER: admin
          BOOTSTRAP_BROKER_JMX_PASSWORD: password

          # Kerberos authentication arguments
          TLS_CA_FILE: "/path/to/CA.pem"
          TLS_CERT_FILE: "/path/to/cert.pem"
          TLS_KEY_FILE: "/path/to/key.pem"
          TLS_INSECURE_SKIP_VERIFY: false
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
    ```
  </Collapser>

  <Collapser
    id="example5"
    title="boootstrap discovery kerberos auth"
  >
    この設定では、Kerberos Auth Clusterの1つのブートストラップブローカからブローカを検出するMetricsのみを収集します。

    ```
    integrations:
      - name: nri-kafka
        env:
          METRICS: true
          CLUSTER_NAME: testcluster1
          AUTODISCOVER_STRATEGY: bootstrap
          BOOTSTRAP_BROKER_HOST: localhost
          BOOTSTRAP_BROKER_KAFKA_PORT: 9092
          BOOTSTRAP_BROKER_KAFKA_PROTOCOL: PLAINTEXT # Currently support PLAINTEXT and SSL
          BOOTSTRAP_BROKER_JMX_PORT: 9999
          BOOTSTRAP_BROKER_JMX_USER: admin
          BOOTSTRAP_BROKER_JMX_PASSWORD: password

          # Kerberos authentication arguments
          SASL_MECHANISM: GSSAPI
          SASL_GSSAPI_REALM: SOMECORP.COM
          SASL_GSSAPI_SERVICE_NAME: Kafka
          SASL_GSSAPI_USERNAME: kafka
          SASL_GSSAPI_KEY_TAB_PATH: /etc/newrelic-infra/kafka.keytab
          SASL_GSSAPI_KERBEROS_CONFIG_PATH: /etc/krb5.conf
          SASL_GSSAPI_DISABLE_FAST_NEGOTIATION: false
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
    ```
  </Collapser>

  <Collapser
    id="example6"
    title="zookeeper discovery topic bucket"
  >
    この構成では、トピックの収集を3つの異なるインスタンスに分割してMetricsを収集します。

    ```
    integrations:
      - name: nri-kafka
        env:
          METRICS: true
          CLUSTER_NAME: testcluster1
          KAFKA_VERSION: "1.0.0"
          AUTODISCOVER_STRATEGY: zookeeper
          ZOOKEEPER_HOSTS: '[{"host": "localhost", "port": 2181}]'
          ZOOKEEPER_AUTH_SECRET: "username:password"
          ZOOKEEPER_PATH: "/kafka-root"
          DEFAULT_JMX_USER: username
          DEFAULT_JMX_PASSWORD: password
          TOPIC_MODE: regex
          TOPIC_REGEX: 'topic\d+'
          TOPIC_BUCKET: '1/3'
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
      - name: nri-kafka
        env:
          METRICS: true
          CLUSTER_NAME: testcluster1
          KAFKA_VERSION: "1.0.0"
          AUTODISCOVER_STRATEGY: zookeeper
          ZOOKEEPER_HOSTS: '[{"host": "localhost", "port": 2181}]'
          ZOOKEEPER_AUTH_SECRET: "username:password"
          ZOOKEEPER_PATH: "/kafka-root"
          DEFAULT_JMX_USER: username
          DEFAULT_JMX_PASSWORD: password
          TOPIC_MODE: regex
          TOPIC_REGEX: 'topic\d+'
          TOPIC_BUCKET: '2/3'
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
      - name: nri-kafka
        env:
          METRICS: true
          CLUSTER_NAME: testcluster1
          KAFKA_VERSION: "1.0.0"
          AUTODISCOVER_STRATEGY: zookeeper
          ZOOKEEPER_HOSTS: '[{"host": "localhost", "port": 2181}]'
          ZOOKEEPER_AUTH_SECRET: "username:password"
          ZOOKEEPER_PATH: "/kafka-root"
          DEFAULT_JMX_USER: username
          DEFAULT_JMX_PASSWORD: password
          TOPIC_MODE: regex
          TOPIC_REGEX: 'topic\d+'
          TOPIC_BUCKET: '3/3'
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
    ```
  </Collapser>

  <Collapser
    id="example7"
    title="java コンシューマー& プロデューサー"
  >
    ここでは、JavaのコンシューマとプロデューサからJMXメトリクスを収集する例を示します。

    ```
    integrations:
      - name: nri-kafka
        env:
          METRICS: "true"
          CLUSTER_NAME: "testcluster3"
          PRODUCERS: '[{"name": "myProducer", "host": "localhost", "port": 24, "username": "me", "password": "secret"}]'
          CONSUMERS: '[{"name": "myConsumer", "host": "localhost", "port": 24, "username": "me", "password": "secret"}]'
          DEFAULT_JMX_HOST: "localhost"
          DEFAULT_JMX_PORT: "9999"
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
    ```
  </Collapser>

  <Collapser
    id="example8"
    title="コンシューマー・オフセット"
  >
    この構成では、クラスタのコンシューマ・オフセット・メトリクスとインベントリを収集します。

    ```
    integrations:
      - name: nri-kafka
        env:
          CONSUMER_OFFSET: true
          CLUSTER_NAME: testcluster3
          AUTODISCOVER_STRATEGY: bootstrap
          BOOTSTRAP_BROKER_HOST: localhost
          BOOTSTRAP_BROKER_KAFKA_PORT: 9092
          BOOTSTRAP_BROKER_KAFKA_PROTOCOL: PLAINTEXT
          # A regex pattern that matches the consumer groups to collect metrics from
          CONSUMER_GROUP_REGEX: '.*'
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
    ```
  </Collapser>
</CollapserGroup>

## データの検索と使用 [#find-and-use]

このサービスからのデータは、[インテグレーションダッシュボード](/docs/integrations/new-relic-integrations/getting-started/infrastructure-integration-dashboards-charts)にレポートされます。

Kafkaのデータは、以下の [イベントタイプに添付されています。](/docs/using-new-relic/data/understand-data/new-relic-data-types#events-new-relic):

* [`KafkaBrokerSample`](#broker-sample)
* [`KafkaTopicSample`](#topic-sample)
* [`KafkaProducerSample`](#producer-sample)
* [`KafkaConsumerSample`](#consumer-sample)
* [`KafkaOffsetSample`](#offset-sample)

トラブルシューティング目的で、またはチャートとダッシュボードを作成するために、[このデータのクエリ](/docs/using-new-relic/data/understand-data/query-new-relic-data)を行えます。

データの検索・使用方法の詳細については、 [インテグレーションデータを理解する](/docs/infrastructure/integrations/find-use-infrastructure-integration-data)を参照してください。

## メトリックデータ [#metrics]

Kafkaインテグレーションでは、以下のメトリックデータ属性を収集します。各メトリック名の前には、 `broker.` や `consumer.` のように、カテゴリインジケータとピリオドが付いています。

### KafkaBrokerSampleイベント [#broker-sample]

<table>
  <thead>
    <tr>
      <th style={{ width: "350px" }}>
        メトリック
      </th>

      <th>
        説明
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `broker.bytesWrittenToTopicPerSecond`
      </td>

      <td>
        ブローカーが1秒あたりにトピックに書き込んだバイト数。
      </td>
    </tr>

    <tr>
      <td>
        `ブローカー.IOInPerSecond`
      </td>

      <td>
        クラスター内のブローカーへのネットワークIOを1秒あたりのバイト数で表示しています。
      </td>
    </tr>

    <tr>
      <td>
        `broker.IOutPerSecond`
      </td>

      <td>
        クラスター内のブローカーのネットワークIOアウト（バイト/秒）。
      </td>
    </tr>

    <tr>
      <td>
        `broker.logFlushPerSecond`
      </td>

      <td>
        ログ・フラッシュ・レート
      </td>
    </tr>

    <tr>
      <td>
        `broker.messagesInPerSecond`
      </td>

      <td>
        着信メッセージ数/秒
      </td>
    </tr>

    <tr>
      <td>
        `follower.requestExpirationPerSecond`
      </td>

      <td>
        フォロワーに対するリクエストの失効率（1秒あたりの退避数）。
      </td>
    </tr>

    <tr>
      <td>
        `net.bytesRejectedPerSecond`
      </td>

      <td>
        拒否されたバイト数/秒
      </td>
    </tr>

    <tr>
      <td>
        `replication.isrExpandsPerSecond`
      </td>

      <td>
        ISRプールに参加するレプリカの割合。
      </td>
    </tr>

    <tr>
      <td>
        `replication.isrShrinksPerSecond`
      </td>

      <td>
        ISRプールから離れるレプリカの割合。
      </td>
    </tr>

    <tr>
      <td>
        `replication.leaderElectionPerSecond`
      </td>

      <td>
        リーダー選出率。
      </td>
    </tr>

    <tr>
      <td>
        `replication.uncleanLeaderElectionPerSecond`
      </td>

      <td>
        汚れたリーダーの選出率
      </td>
    </tr>

    <tr>
      <td>
        `replication.unreplicatedPartitions`
      </td>

      <td>
        複製されていないパーティションの数。
      </td>
    </tr>

    <tr>
      <td>
        `request.avgTimeFetch`
      </td>

      <td>
        フェッチリクエスト1回あたりの平均時間（単位：ミリ秒）。
      </td>
    </tr>

    <tr>
      <td>
        `request.avgTimeMetadata`
      </td>

      <td>
        メタデータ・リクエストの平均時間（単位：ミリ秒）。
      </td>
    </tr>

    <tr>
      <td>
        `request.avgTimeMetadata99Percentile`
      </td>

      <td>
        99パーセンタイルのメタデータ・リクエストの時間（ミリ秒）。
      </td>
    </tr>

    <tr>
      <td>
        `request.avgTimeOffset`
      </td>

      <td>
        オフセットリクエストの平均時間（単位：ミリ秒）。
      </td>
    </tr>

    <tr>
      <td>
        `request.avgTimeOffset99Percentile`
      </td>

      <td>
        99パーセンタイルのオフセット要求の時間（単位：ミリ秒）。
      </td>
    </tr>

    <tr>
      <td>
        `request.avgTimeProduceRequest`
      </td>

      <td>
        プロデュースリクエストの平均時間（単位：ミリ秒）。
      </td>
    </tr>

    <tr>
      <td>
        `request.avgTimeUpdateMetadata`
      </td>

      <td>
        メタデータを更新するリクエストの平均時間（ミリ秒）。
      </td>
    </tr>

    <tr>
      <td>
        `request.avgTimeUpdateMetadata99Percentile`
      </td>

      <td>
        99パーセンタイルのメタデータ更新要求の時間（単位：ミリ秒）。
      </td>
    </tr>

    <tr>
      <td>
        `request.clientFetchesFailedPerSecond`
      </td>

      <td>
        クライアントのフェッチリクエストの失敗数/秒。
      </td>
    </tr>

    <tr>
      <td>
        `request.fetchTime99Percentile`
      </td>

      <td>
        99パーセンタイルのフェッチリクエストの時間（単位：ミリ秒）。
      </td>
    </tr>

    <tr>
      <td>
        `request.handlerIdle`
      </td>

      <td>
        リクエストハンドラースレッドがアイドル状態である時間の平均割合。
      </td>
    </tr>

    <tr>
      <td>
        `request.produceRequestsFailedPerSecond`
      </td>

      <td>
        1秒あたりの失敗したプロダクション・リクエスト
      </td>
    </tr>

    <tr>
      <td>
        `request.produceTime99Percentile`
      </td>

      <td>
        99パーセンタイルのプロデュース依頼にかかる時間。
      </td>
    </tr>

    <tr>
      <td>
        `topic.diskSize`
      </td>

      <td>
        ディスク内トピック・サイズ。COLLECT_TOPIC_SIZEが有効な場合のみ存在します。
      </td>
    </tr>

    <tr>
      <td>
        `トピック.オフセット`
      </td>

      <td>
        トピック・オフセット。COLLECT_TOPIC_OFFSETが有効な場合のみ存在します。
      </td>
    </tr>
  </tbody>
</table>

### KafkaConsumerSampleイベント [#consumer-sample]

<table>
  <thead>
    <tr>
      <th style={{ width: "350px" }}>
        メトリック
      </th>

      <th>
        説明
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `consumer.avgFetchSizeInBytes`
      </td>

      <td>
        特定のトピックのリクエストごとに取得されたバイト数の平均値。
      </td>
    </tr>

    <tr>
      <td>
        `consumer.avgRecordConsumedPerTopic`
      </td>

      <td>
        特定のトピックに対する各リクエストの平均レコード数。
      </td>
    </tr>

    <tr>
      <td>
        `consumer.avgRecordConsumedPerTopicPerSecond`
      </td>

      <td>
        特定のトピックについて、1秒間に消費されるレコードの平均数（単位：レコード/秒）。
      </td>
    </tr>

    <tr>
      <td>
        `consumer.bytesInPerSecond`
      </td>

      <td>
        コンシューマーバイト/秒。
      </td>
    </tr>

    <tr>
      <td>
        `consumer.fetchPerSecond`
      </td>

      <td>
        コンシューマがフェッチリクエストをブレイクスルーに送信する際の最小レート（1秒あたりのリクエスト数）。
      </td>
    </tr>

    <tr>
      <td>
        `consumer.maxFetchSizeInBytes`
      </td>

      <td>
        特定のトピックのリクエストごとに取得される最大バイト数。
      </td>
    </tr>

    <tr>
      <td>
        `consumer.maxLag`
      </td>

      <td>
        最大限のコンシューマー・ラグ。
      </td>
    </tr>

    <tr>
      <td>
        `consumer.messageConsumptionPerSecond`
      </td>

      <td>
        コンシューマのメッセージ消費率（1秒あたりのメッセージ数）。
      </td>
    </tr>

    <tr>
      <td>
        `consumer.offsetKafkaCommitsPerSecond`
      </td>

      <td>
        Kafkaへのオフセットコミットの割合（コミット数/秒）。
      </td>
    </tr>

    <tr>
      <td>
        `consumer.offsetZooKeeperCommitsPerSecond`
      </td>

      <td>
        ZooKeeper へのオフセットコミットの割合 (Write per Second)。
      </td>
    </tr>

    <tr>
      <td>
        `consumer.requestsExpiredPerSecond`
      </td>

      <td>
        遅延したコンシューマ・リクエストの失効率（1秒あたりのエヴィジョン数）。
      </td>
    </tr>
  </tbody>
</table>

### KafkaProducerSampleイベント [#producer-sample]

<table>
  <thead>
    <tr>
      <th style={{ width: "350px" }}>
        メトリック
      </th>

      <th>
        説明
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `producer.ageMetadataUsedInMilliseconds`
      </td>

      <td>
        現在使用されているプロデューサーメタデータの年齢（秒単位）。
      </td>
    </tr>

    <tr>
      <td>
        `producer.availableBufferInBytes`
      </td>

      <td>
        使用されていないバッファメモリの総量（単位：バイト）。
      </td>
    </tr>

    <tr>
      <td>
        `producer.avgBytesSentPerRequestInBytes`
      </td>

      <td>
        パーティションごとのリクエストごとの平均送信バイト数。
      </td>
    </tr>

    <tr>
      <td>
        `producer.avgCompressionRateRecordBatches`
      </td>

      <td>
        レコードバッチの平均圧縮率
      </td>
    </tr>

    <tr>
      <td>
        `producer.avgRecordAccumulatorsInMilliseconds`
      </td>

      <td>
        レコードバッチがレコードアキュムレータにかかった平均時間（ms）。
      </td>
    </tr>

    <tr>
      <td>
        `producer.avgRecordSizeInBytes`
      </td>

      <td>
        平均レコードサイズ（単位：バイト）。
      </td>
    </tr>

    <tr>
      <td>
        `producer.avgRecordsSentPerSecond`
      </td>

      <td>
        1秒間に送信されるレコードの平均数。
      </td>
    </tr>

    <tr>
      <td>
        `producer.avgRecordsSentPerTopicPerSecond`
      </td>

      <td>
        トピックの1秒あたりの平均送信レコード数。
      </td>
    </tr>

    <tr>
      <td>
        `プロデューサー.AbgRequestLatencyPerSecond`
      </td>

      <td>
        プロデューサーの平均リクエストレイテンシー。
      </td>
    </tr>

    <tr>
      <td>
        `producer.avgThrottleTime`
      </td>

      <td>
        ブローカーによってリクエストがスロットルされた平均時間（ミリ秒）。
      </td>
    </tr>

    <tr>
      <td>
        `producer.bufferMemoryAvailableInBytes`
      </td>

      <td>
        クライアントが使用できるバッファメモリの最大量（単位：バイト）。
      </td>
    </tr>

    <tr>
      <td>
        `producer.bufferpoolWaitTime`
      </td>

      <td>
        アペンダーがスペースの割り当てを待つ時間の派閥。
      </td>
    </tr>

    <tr>
      <td>
        `producer.bytesOutPerSecond`
      </td>

      <td>
        プロデューサーバイト/秒アウト。
      </td>
    </tr>

    <tr>
      <td>
        `producer.compressionRateRecordBatches`
      </td>

      <td>
        あるトピックのレコードバッチの平均圧縮率。
      </td>
    </tr>

    <tr>
      <td>
        `プロデューサー.iOWaitTime`
      </td>

      <td>
        プロデューサーI/Oの待ち時間（ミリ秒）。
      </td>
    </tr>

    <tr>
      <td>
        `producer.maxBytesSentPerRequestInBytes`
      </td>

      <td>
        パーティションごとに送信される最大バイト数 per-request。
      </td>
    </tr>

    <tr>
      <td>
        `producer.maxRecordSizeInBytes`
      </td>

      <td>
        最大レコードサイズ（単位：バイト）。
      </td>
    </tr>

    <tr>
      <td>
        `producer.maxRequestLatencyInMilliseconds`
      </td>

      <td>
        最大リクエストレイテンシー（単位：ミリ秒）。
      </td>
    </tr>

    <tr>
      <td>
        `producer.maxThrottleTime`
      </td>

      <td>
        リクエストがブローカによってスロットルされた最大時間（単位：ミリ秒）。
      </td>
    </tr>

    <tr>
      <td>
        `producer.messageRatePerSecond`
      </td>

      <td>
        1秒あたりのプロデューサーメッセージ数
      </td>
    </tr>

    <tr>
      <td>
        `producer.responsePerSecond`
      </td>

      <td>
        1秒あたりのプロデューサーの応答数
      </td>
    </tr>

    <tr>
      <td>
        `producer.requestPerSecond`
      </td>

      <td>
        1秒あたりのプロデューサー・リクエストの数。
      </td>
    </tr>

    <tr>
      <td>
        `producer.requestsWaitingResponse`
      </td>

      <td>
        応答を待っている機内リクエストの現在の数。
      </td>
    </tr>

    <tr>
      <td>
        `producer.threadsWaiting`
      </td>

      <td>
        レコードをエンキューするためのバッファメモリを待ってブロックされたユーザースレッドの数。
      </td>
    </tr>
  </tbody>
</table>

### KafkaTopicSampleイベント [#topic-sample]

<table>
  <thead>
    <tr>
      <th style={{ width: "350px" }}>
        メトリック
      </th>

      <th>
        説明
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `topic.diskSize`
      </td>

      <td>
        ブローカーあたりの現在のトピックのディスクサイズ（単位：バイト）。
      </td>
    </tr>

    <tr>
      <td>
        `トピック.partitionsWithNonPreferredLeader`
      </td>

      <td>
        トピックごとのパーティションのうち、優先するレプリカに導かれていないパーティションの数。
      </td>
    </tr>

    <tr>
      <td>
        `topic.respondMetaData`
      </td>

      <td>
        メタデータの要求に応えたトピックの数
      </td>
    </tr>

    <tr>
      <td>
        `topic.retentionSizeOrTime`
      </td>

      <td>
        パーティションをサイズで保持するか、サイズと時間の両方で保持するか。値が0の場合は時間、値が1の場合はサイズと時間の両方です。
      </td>
    </tr>

    <tr>
      <td>
        `トピック.underReplicatedPartitions`
      </td>

      <td>
        アンダーレプリケートされているトピックごとのパーティションの数。
      </td>
    </tr>
  </tbody>
</table>

### KafkaOffsetSampleイベント [#offset-sample]

<table>
  <thead>
    <tr>
      <th style={{ width: "350px" }}>
        メトリック
      </th>

      <th>
        説明
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `consumer.offset`
      </td>

      <td>
        消費者グループがパーティション上で最後に消費したオフセット。
      </td>
    </tr>

    <tr>
      <td>
        `コンシューマー・ラグ`
      </td>

      <td>
        ブローカーのハイウォーターマークと消費者のオフセットの差(`consumer.hwm` - `consumer.offset`)。
      </td>
    </tr>

    <tr>
      <td>
        `consumer.hwm`
      </td>

      <td>
        パーティションに書き込まれた最後のメッセージのオフセット（ハイウォーターマーク）。
      </td>
    </tr>

    <tr>
      <td>
        `consumer.totalLag`
      </td>

      <td>
        コンシューマが消費するパーティション間のラグの合計。
      </td>
    </tr>

    <tr>
      <td>
        `consumerGroup.totalLag`
      </td>

      <td>
        `consumerGroup` によって消費されたすべてのパーティションのラグの合計です。
      </td>
    </tr>

    <tr>
      <td>
        `consumerGroup.maxLag`
      </td>

      <td>
        `consumerGroup` によって消費されるすべてのパーティション間の最大ラグです。
      </td>
    </tr>
  </tbody>
</table>

## インベントリデータ [#inventory]

Kafka インテグレーションは、デフォルト以外のブローカとトピックの設定パラメータを取得し、ZooKeeper から報告されたトピック・パーティション・スキームを収集します。このデータは、 [Inventory UI ページ](/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/infrastructure-inventory-page-search-your-entire-infrastructure) の `config/kafka` source で利用できます。

## トラブルシューティング

トラブルシューティングのヒント

<CollapserGroup>
  <Collapser
    id="duplicate-info"
    title="重複したデータが報告される"
  >
    プロデューサーやコンシューマーを監視しているエージェントで、 `Topic mode` が `All`: に設定されている場合、重複したデータが報告されるという問題があります。重複データを止めるには、 [設定オプション](#config) `Collect topic size` が false に設定されていることを確認してください。
  </Collapser>

  ' '

  <Collapser
    id="zookeeper-node-not-found"
    title="Integration is logging errors 'zk: node not found'."
  >
    `zookeeper_path` が [設定ファイル](#config) で正しく設定されていることを確認してください。
  </Collapser>

  <Collapser
    id="jmx-connection-errors"
    title="JMXの接続エラー"
  >
    Kafka統合では、 `nrjmx` というJMXヘルパーツールを使用して、ブローカー、コンシューマー、およびプロデューサーからJMXメトリクスを取得します。クラスター内のすべてのブローカーでJMXを有効にして構成する必要があります。また、統合を実行しているホストからJMXポートを介したブローカーへの接続を許可するように、ファイアウォールを調整する必要があります。

    JMX が正しく設定されているかどうかを確認するには、Kafka インテグレーションを実行しているマシンから、各ブローカーに対して次のコマンドを実行します。ハイライトされている <var>PORT</var>, <var>USERNAME</var>, <var>PASSWORD</var> トークンを、ブローカーの対応するJMX設定に置き換えます。

    ```
    $ echo "*:*" | nrjmx -hostname <var>HOSTNAME</var> -port <var>PORT</var> -v -username <var>USERNAME</var> -password <var>PASSWORD</var>
    ```

    このコマンドを実行すると、エラーなしで一連の長いメトリクスを示す出力が生成されます。
  </Collapser>

  <Collapser
    id="kerberos-authentication"
    title="Kerberos認証の失敗"
  >
    インテグレーションでは、以下のようなエラーが表示されることがあります。

    ```
    KRB Error: (6) KDC_ERR_C_PRINCIPAL_UNKNOWN Client not found in Kerberos database
    ```

    kinitコマンドでkeytabを確認します。ハイライトされたフィールドをあなたの値に置き換えてください。

    ```
    $ kinit -k -t <var>KEY_TAB_PATH</var> <var>USERNAME</var>
    ```

    ユーザー名とkeytabの組み合わせが正しければ、上記のコマンドはエラーを表示せずに終了します。

    klistコマンドでレルムを確認します。

    ```
    $ klist |grep "Default principal:"
    ```

    このように表示されます。

    ```
    Default principal: johndoe@a_realm_name
    ```

    印刷されたユーザー名とレルムが、統合構成の `sasl_gssapi_realm` および `sasl_gssapi_username` パラメータと一致していることを確認します。
  </Collapser>
</CollapserGroup>

## ソースコードのチェック [#source-code]

このインテグレーションは、オープンソース・ソフトウェアです。つまり、 [そのソースコードを閲覧して](https://github.com/newrelic/nri-kafka "新しいウィンドウにリンクが開きます。") 改良点を送ったり、自分でフォークを作って構築することができます。